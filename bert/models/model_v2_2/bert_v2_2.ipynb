{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2.2 concatenates all texts by only keeping sentences where bias is present. This needs a new preprocessing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas transformers torch datasets numpy openpyxl scikit-learn\n",
    "# !pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers, torch\n",
    "\n",
    "\"\"\"\n",
    "Remove uneecessay new lines\n",
    "remove duplicates within one cell\n",
    "Remove links?\n",
    "use keywords to make sure that correct classification is done\n",
    "make validation set more class balanced, i.e. equal num of examples for each category\n",
    "\"\"\"\n",
    "# use keras instead of huggung face to make it easier to work with messing with layers\n",
    "# keep latest entries only in original clean data\n",
    "# double or triple (for some biases) rows that have social, gender, or subjective bias\n",
    "# remove entries greater than 512 words to remove noise\n",
    "# enchance data by repeating key terms\n",
    "# cut 512 from middle of the dataset\n",
    "# try giving it only the labels with 5 word context\n",
    "# try doing subtext technique to give it 1000 words\n",
    "\n",
    "# load data and rename TextEntry column\n",
    "df = pd.read_excel(\"../../../carlos_data/bert_v2_2_preprocessed_data_v3.xlsx\")\n",
    "df = df.rename(columns={\"TextEntry\":\"Description\"})\n",
    "df.drop(columns=['Subjective Label', 'Gender Label', 'Jargon Label', 'Social Label'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['ObjectID', 'Description', 'Subjective', 'Gender', 'Jargon', 'Social'],\n",
      "        num_rows: 1444\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['ObjectID', 'Description', 'Subjective', 'Gender', 'Jargon', 'Social'],\n",
      "        num_rows: 180\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['ObjectID', 'Description', 'Subjective', 'Gender', 'Jargon', 'Social'],\n",
      "        num_rows: 181\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import transformers, torch\n",
    "\n",
    "# convert data to dictionary\n",
    "data = df.to_dict(\"records\")\n",
    "# Split the data into train and validation and test sets\n",
    "from sklearn.model_selection import train_test_split \n",
    "train_dict, test_dict = train_test_split(data, test_size=0.20, random_state=42)\n",
    "test_dict, validation_dict = train_test_split(test_dict, test_size=0.50, random_state=42)\n",
    "\n",
    "# Create Dataset objects\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_list(train_dict)\n",
    "test_dataset = Dataset.from_list(test_dict)\n",
    "validation_dataset = Dataset.from_list(validation_dict)\n",
    "\n",
    "# Create DatasetDict\n",
    "from datasets import DatasetDict\n",
    "dataset = DatasetDict({\n",
    "\t\"train\": train_dataset,\n",
    "\t\"test\": test_dataset,\n",
    "\t\"validation\": validation_dataset\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Texts length distribution (number of words)')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGzCAYAAADUo+joAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLyUlEQVR4nO3de1xVVf7/8fc54AEBAREBLyiUlpkoiYGYpo0UpVNZOpnfZrxkaZmm0U0dU5ua6PKzsYtlfpvRnMl0bMz6mlmIZqXkDS9ZZmreUgEVAUUFgfX7w+Hk2YAiIgfs9Xx0Hsnaa6/92YuDvN23YzPGGAEAAMDJ7u4CAAAAahsCEgAAgAUBCQAAwIKABAAAYEFAAgAAsCAgAQAAWBCQAAAALAhIAAAAFgQkAAAACwIScJbBgwcrIiLC3WWc16xZs2Sz2bRu3bpqHbe8/bfZbJo8eXK1bqc8X375pWw2m7788ktnW48ePdSuXbtLvm1J2r17t2w2m2bNmlUj2ytPr1699OCDD7pt+5VROk//7//9P3eXUinHjx/XAw88oLCwMNlsNo0ZM8bdJVVaVf4+WrJkifz8/HTo0KFLU9RvCAEJ1cZms1XqdfYvwItx4MABTZ48WRs3bqyW8Wqjt956y62/sKtqzpw5mjp1qrvLKFdtrW3lypX64osv9PTTT7u7lMvKCy+8oFmzZunhhx/WP//5T/3pT39yd0mX1K233qpWrVopOTnZ3aXUeZ7uLgCXj3/+858uX8+ePVspKSll2q+55ppq2d6BAwf07LPPKiIiQtHR0dUyZm3z1ltvKTg4WIMHD3ZbDSdPnpSn54X9VTFnzhxt2bLlgv61fuONN+rkyZNyOBwXWOGFqai2li1b6uTJk6pXr94l3X5FXnnlFfXs2VOtWrVyy/YvV8uWLVPnzp01adIkd5dSY4YPH64nnnhCzz77rBo0aODucuosAhKqzR//+EeXr7/99lulpKSUaUfd4u3tfUnHP3XqlBwOh+x2+yXf1rnYbDa3bT8rK0uffvqppk+f7pbt10b5+fny9fW96HGysrLUtm3baqio+p393q9Offv21ahRozR//nzdf//91Tr2bwmn2FCjSkpKNHXqVF177bXy9vZWaGiohg8frqNHjzr7TJo0SXa7XampqS7rDhs2TA6HQ5s2bdKXX36p66+/XpI0ZMgQ5+m70tNR27dvV9++fRUWFiZvb281b95c9957r3Jzcy9JzZIUERGh3//+9/rmm28UGxsrb29vXXHFFZo9e3aZMTdv3qzu3burfv36at68uZ5//nnNnDlTNptNu3fvdo73/fffa8WKFc7969Gjh8s4BQUFSkpKUuPGjeXr66u77rqr0tceLFy4UO3atZO3t7fatWunjz76qNx+1muQjh07pjFjxigiIkJeXl4KCQnRzTffrPT0dElnrhv69NNPtWfPHmfdpddRlF5nNHfuXE2YMEHNmjWTj4+P8vLyyr0GqdT69evVpUsX1a9fX5GRkWWCROk1WaVzV8o65rlqq+gapGXLlqlbt27y9fVVYGCg7rzzTm3dutWlz+TJk2Wz2bRjxw4NHjxYgYGBCggI0JAhQ3TixImKvwn/9emnn6qoqEgJCQnl7tfKlSvP+32u6FqxiIgIlyOQpWN+8803evTRR9W4cWMFBgZq+PDhKiwsVE5OjgYOHKiGDRuqYcOGeuqpp2SMKbfuv/3tb2rZsqXq16+v7t27a8uWLWX6/Pjjj+rXr5+CgoLk7e2tTp066ZNPPil3P1esWKERI0YoJCREzZs3P+ecZWVlaejQoQoNDZW3t7c6dOig9957z7m89Hu/a9cuffrpp87vt/U9Uuruu+9Wx44dXdpuv/122Ww2l3pXr14tm82mzz77zNn2888/6w9/+IOCgoLk4+Ojzp0769NPP3UZ61zvfanyP49z585VTEyMGjRoIH9/f0VFRem1115z6RMSEqL27dvr448/Pucc4tw4goQaNXz4cM2aNUtDhgzRo48+ql27dunNN9/Uhg0btHLlStWrV08TJkzQ//3f/2no0KH67rvv1KBBA33++ef63//9Xz333HPq0KGDMjMz9Ze//EUTJ07UsGHD1K1bN0lSly5dVFhYqMTERBUUFGjUqFEKCwvT/v37tWjRIuXk5CggIKDaay61Y8cO9evXT0OHDtWgQYP0j3/8Q4MHD1ZMTIyuvfZaSdL+/ft10003yWazady4cfL19dW7774rLy8vl+1OnTpVo0aNkp+fn/785z9LkkJDQ136jBo1Sg0bNtSkSZO0e/duTZ06VSNHjtS8efPOuU9ffPGF+vbtq7Zt2yo5OVlHjhzRkCFDzvtLSZIeeughffjhhxo5cqTatm2rI0eO6JtvvtHWrVvVsWNH/fnPf1Zubq5++eUX/e1vf5Mk+fn5uYzx3HPPyeFw6IknnlBBQcE5T6sdPXpUvXr10j333KMBAwbo3//+tx5++GE5HI4L/tdxZWo729KlS3Xbbbfpiiuu0OTJk3Xy5Em98cYbuuGGG5Senl7mAtp77rlHkZGRSk5OVnp6ut59912FhITopZdeOmddq1atUqNGjdSyZctyl1f1+3wupT8bzz77rL799lvNmDFDgYGBWrVqlVq0aKEXXnhBixcv1iuvvKJ27dpp4MCBLuvPnj1bx44d0yOPPKJTp07ptdde0+9+9zt99913zvfp999/rxtuuEHNmjXT2LFj5evrq3//+9/q06eP/vOf/+iuu+5yGXPEiBFq3LixJk6cqPz8/AprP3nypHr06KEdO3Zo5MiRioyM1Pz58zV48GDl5ORo9OjRuuaaa/TPf/5Tjz32mJo3b67HH39cktS4ceNyx+zWrZs+/vhj5eXlyd/fX8YYrVy5Una7XV9//bXuuOMOSdLXX38tu92uG264QZKUmZmpLl266MSJE3r00UfVqFEjvffee7rjjjv04YcfltnH8t77lf15TElJ0YABA9SzZ0/ne2rr1q1auXKlRo8e7dI3JiZGCxcurHAOUQkGuEQeeeQRc/Zb7OuvvzaSzPvvv+/Sb8mSJWXav/vuO+NwOMwDDzxgjh49apo1a2Y6depkTp8+7eyzdu1aI8nMnDnTZbwNGzYYSWb+/PkXXPOgQYNMy5Ytq1Rzy5YtjSTz1VdfOduysrKMl5eXefzxx51to0aNMjabzWzYsMHZduTIERMUFGQkmV27djnbr732WtO9e/cydc6cOdNIMgkJCaakpMTZ/thjjxkPDw+Tk5Nzzv2Mjo42TZo0cen3xRdfGEku+2+MMZLMpEmTnF8HBASYRx555Jzj9+7du8w4xhizfPlyI8lcccUV5sSJE+UuW758ubOte/fuRpKZMmWKs62goMBER0ebkJAQU1hYaIz5dT7OnruKxqyotl27dpV5P5Vu58iRI862TZs2GbvdbgYOHOhsmzRpkpFk7r//fpcx77rrLtOoUaMy27Lq2rWriYmJKdN+Id9n6/epVMuWLc2gQYPKjJmYmOgyZnx8vLHZbOahhx5ythUVFZnmzZu7vAdL56l+/frml19+cbavXr3aSDKPPfaYs61nz54mKirKnDp1ytlWUlJiunTpYlq3bl2mpq5du5qioqJzzNQZU6dONZLMv/71L2dbYWGhiY+PN35+fiYvL89l/3v37n3eMUv/Plm8eLExxpjNmzcbSeYPf/iDiYuLc/a74447zHXXXef8esyYMUaS+frrr51tx44dM5GRkSYiIsIUFxcbY8793q/sz+Po0aONv79/pebohRdeMJJMZmbmefuifJxiQ42ZP3++AgICdPPNN+vw4cPOV0xMjPz8/LR8+XJn33bt2unZZ5/Vu+++q8TERB0+fFjvvfdepS4WLj1C9Pnnn1fq9EZ11SxJbdu2dR7Nks78a/Xqq6/Wzz//7GxbsmSJ4uPjXS4sDwoK0n333XfB9Q0bNkw2m835dbdu3VRcXKw9e/ZUuM7Bgwe1ceNGDRo0yOVo2s0331ypazUCAwO1evVqHThw4ILrLTVo0CDVr1+/Un09PT01fPhw59cOh0PDhw9XVlaW1q9fX+Uazqd0ngYPHqygoCBne/v27XXzzTdr8eLFZdZ56KGHXL7u1q2bjhw54jyNUpEjR46oYcOGFS6vyvf5fIYOHeoyZlxcnIwxGjp0qLPNw8NDnTp1cnn/lurTp4+aNWvm/Do2NlZxcXHOecnOztayZct0zz336NixY86fnSNHjigxMVHbt2/X/v37XcZ88MEH5eHhcd7aFy9erLCwMA0YMMDZVq9ePT366KM6fvy4VqxYUfmJ+K/rrrtOfn5++uqrrySdOVLUvHlzDRw4UOnp6Tpx4oSMMfrmm29cfsYXL16s2NhYde3a1dnm5+enYcOGaffu3frhhx9ctmN971/Iz2NgYKDy8/OVkpJy3v0pfT8dPnz4AmYBZyMgocZs375dubm5CgkJUePGjV1ex48fV1ZWlkv/J598Uh06dNCaNWs0adKkSl9oGRkZqaSkJL377rsKDg5WYmKipk2bVqXrjy605hYtWpQZo2HDhi7XK+3Zs6fcO5WqcveSdXulfylar486W+kv1datW5dZdvXVV593my+//LK2bNmi8PBwxcbGavLkyeX+Aj2XyMjISvdt2rRpmYt1r7rqKkmq8HqS6lA6T+XNyTXXXKPDhw+XOQ1Ule9HKVPBdT4XO25lxyz95RweHl6mvbztlPf+ueqqq5zfkx07dsgYo2eeeabMz07pHWXWn5/Kvi/27Nmj1q1bl7m4ufQO2aoERw8PD8XHx+vrr7+WdCYgdevWTV27dlVxcbG+/fZb/fDDD8rOznYJSHv27KnwPVJeLdZ9vJCfxxEjRuiqq67SbbfdpubNm+v+++/XkiVLyt2f0vfT2SEYF4ZrkFBjSkpKFBISovfff7/c5dZrA37++Wdt375dkvTdd99d0LamTJmiwYMH6+OPP9YXX3yhRx99VMnJyfr2228rdZ1NVWuu6F+/5/rldzFqenvSmetsunXrpo8++khffPGFXnnlFb300ktasGCBbrvttkqNUdmjR5VV0S+B4uLiat3O+VT1+9GoUaNzhp2L+T5XNAcVjVlee1XeTyUlJZKkJ554QomJieX2sf6joLrfFxeqa9eu+utf/6pTp07p66+/1p///GcFBgaqXbt2+vrrr53XVp0dkC7UxexjSEiINm7cqM8//1yfffaZPvvsM82cOVMDBw50uUBd+jU8BwcHV3l7v3UEJNSYK6+8UkuXLtUNN9xw3r8kSkpKNHjwYPn7+2vMmDF64YUX1K9fP919993OPuf7l1FUVJSioqI0YcIErVq1SjfccIOmT5+u559//pLUXFktW7bUjh07yrSX13Yp/vVXeiFwafg827Zt2yo1RpMmTTRixAiNGDFCWVlZ6tixo/761786A1J11n3gwIEyt3z/9NNPkuS8SLr0iEpOTo7LuuUdSahsbaXzVN6c/PjjjwoODq6W29AlqU2bNvrPf/5zUWM0bNiwzP4XFhbq4MGDFzVuRcp7//z000/O78kVV1wh6cypL+vdeRerZcuW2rx5s0pKSlyOIv3444/O5VXRrVs3FRYW6oMPPtD+/fudQejGG290BqSrrrrK5WaJli1bVvgeqUwtF/rz6HA4dPvtt+v2229XSUmJRowYoXfeeUfPPPOMS+DctWuXgoODK7woHefHKTbUmHvuuUfFxcV67rnnyiwrKipy+cv91Vdf1apVqzRjxgw999xz6tKlix5++GGX8+mlv5ysvxTy8vJUVFTk0hYVFSW73a6CgoJLVnNlJSYmKi0tzeUJ4NnZ2eUepfL19a3SNs6lSZMmio6O1nvvvedy2jElJaXM9RJWxcXFZU5VhoSEqGnTpi5z6+vrW6VTmuUpKirSO++84/y6sLBQ77zzjho3bqyYmBhJZ4KsJOf1I6W1zpgxo8x4la3t7Hk6+3uwZcsWffHFF+rVq1dVd6mM+Ph4HT169IJPVZ7tyiuvdNl/SZoxY8YlO4q2cOFCl2uI1qxZo9WrVztDckhIiHr06KF33nmn3JB2MR+F0atXL2VkZLjcxVdUVKQ33nhDfn5+6t69e5XGjYuLU7169fTSSy8pKCjIeedpt27d9O2332rFihVljh716tVLa9asUVpamrMtPz9fM2bMUERExHkvDbiQn8cjR464fG2329W+fXtJKvN32/r16xUfH1/JPUd5OIKEGtO9e3cNHz5cycnJ2rhxo2655RbVq1dP27dv1/z58/Xaa6+pX79+2rp1q5555hkNHjxYt99+u6Qzz0mJjo7WiBEj9O9//1vSmV8IgYGBmj59uho0aCBfX1/FxcVp06ZNGjlypP7whz/oqquuUlFRkf75z3/Kw8NDffv2vSQ1X4innnpK//rXv3TzzTdr1KhRztv8W7RooezsbJcjHDExMXr77bf1/PPPq1WrVgoJCdHvfve7C9peeZKTk9W7d2917dpV999/v7Kzs/XGG2/o2muv1fHjxytc79ixY2revLn69eunDh06yM/PT0uXLtXatWs1ZcoUl7rnzZunpKQkXX/99fLz83N+Ly9U06ZN9dJLL2n37t266qqrNG/ePG3cuFEzZsxwPmLh2muvVefOnTVu3DhlZ2crKChIc+fOLROUL7S2V155Rbfddpvi4+M1dOhQ523+AQEB1fr5dL1795anp6eWLl2qYcOGVWmMBx54QA899JD69u2rm2++WZs2bdLnn39+yU6xtGrVSl27dtXDDz+sgoICTZ06VY0aNdJTTz3l7DNt2jR17dpVUVFRevDBB3XFFVcoMzNTaWlp+uWXX7Rp06YqbXvYsGF65513NHjwYK1fv14RERH68MMPtXLlSk2dOrXKT4/28fFRTEyMvv32W+czkKQzR5Dy8/OVn59fJiCNHTtWH3zwgW677TY9+uijCgoK0nvvvaddu3bpP//5T6UeAlnZn8cHHnhA2dnZ+t3vfqfmzZtrz549euONNxQdHe3yCQVZWVnavHmzHnnkkSrNA/7LXbfP4fJnvc2/1IwZM0xMTIypX7++adCggYmKijJPPfWUOXDggCkqKjLXX3+9ad68eZlb1V977TUjycybN8/Z9vHHH5u2bdsaT09P5y3aP//8s7n//vvNlVdeaby9vU1QUJC56aabzNKlS89bs/U2/8rUXKqi24m7d+9e5lb9DRs2mG7duhkvLy/TvHlzk5ycbF5//XUjyWRkZDj7ZWRkmN69e5sGDRoYSc5xSm+LXrt2rcu45d3WXpH//Oc/5pprrjFeXl6mbdu2ZsGCBeXuv866fbygoMA8+eSTpkOHDqZBgwbG19fXdOjQwbz11lsu6xw/ftz8z//8jwkMDHS5Vbm0vvIewVDRbf7XXnutWbdunYmPjzfe3t6mZcuW5s033yyz/s6dO01CQoLx8vIyoaGhZvz48SYlJaXMmBXVVt5t/sYYs3TpUnPDDTeY+vXrG39/f3P77bebH374waVP6W3+hw4dcmmv6PED5bnjjjtMz549y12/Mt/n4uJi8/TTT5vg4GDj4+NjEhMTzY4dOyq8zd86ZkX7MGjQIOPr6+v8unSeXnnlFTNlyhQTHh5uvLy8TLdu3cymTZvK7NfOnTvNwIEDTVhYmKlXr55p1qyZ+f3vf28+/PDD89Z0LpmZmWbIkCEmODjYOBwOExUVVeZ7Z0zlb/Mv9eSTTxpJ5qWXXnJpb9WqlZFkdu7cWe4+9uvXzwQGBhpvb28TGxtrFi1a5NLnXO99Yyr38/jhhx+aW265xYSEhBiHw2FatGhhhg8fbg4ePOgy1ttvv218fHxcHneAC2cz5hJezQmg0saMGaN33nlHx48fr9Stzri8fP311+rRo4d+/PHHcu9oAirruuuuU48ePZwPQ0XVEJAANzh58qTLRd9HjhzRVVddpY4dO1bqGSe4PJXevv2///u/7i4FddSSJUvUr18//fzzzwoJCXF3OXUaAQlwg+joaPXo0UPXXHONMjMz9fe//10HDhxQamqqbrzxRneXBwC/eVykDbhBr1699OGHH2rGjBmy2Wzq2LGj/v73vxOOAKCW4AgSAACABc9BAgAAsCAgAQAAWHANUhWVlJTowIEDatCgAR8GCABAHWGM0bFjx9S0adNzPsiTgFRFBw4cKPOp1wAAoG7Yt2/fOT+8nIBURaWPst+3b5/8/f3dXA0AAKiMvLw8hYeHn/cjaQhIVVR6Ws3f35+ABABAHXO+y2NqxUXa06ZNU0REhLy9vRUXF6c1a9acs//8+fPVpk0beXt7KyoqSosXL3YuO336tJ5++mlFRUXJ19dXTZs21cCBA3XgwAGXMSIiImSz2VxeL7744iXZPwAAULe4PSCVfqr2pEmTlJ6erg4dOigxMVFZWVnl9l+1apUGDBigoUOHasOGDerTp4/69OmjLVu2SJJOnDih9PR0PfPMM0pPT9eCBQu0bds23XHHHWXG+stf/qKDBw86X6NGjbqk+woAAOoGtz8oMi4uTtdff73efPNNSWfuDgsPD9eoUaM0duzYMv379++v/Px8LVq0yNnWuXNnRUdHa/r06eVuY+3atYqNjdWePXvUokULSWeOII0ZM0ZjxoypUt15eXkKCAhQbm4up9gAAKgjKvv7261HkAoLC7V+/XolJCQ42+x2uxISEpSWllbuOmlpaS79JSkxMbHC/pKUm5srm82mwMBAl/YXX3xRjRo10nXXXadXXnlFRUVFFY5RUFCgvLw8lxcAALg8ufUi7cOHD6u4uFihoaEu7aGhofrxxx/LXScjI6Pc/hkZGeX2P3XqlJ5++mkNGDDAJSk++uij6tixo4KCgrRq1SqNGzdOBw8e1KuvvlruOMnJyXr22WcvZPcAAEAddVnfxXb69Gndc889Msbo7bffdlmWlJTk/HP79u3lcDg0fPhwJScny8vLq8xY48aNc1mn9DZBAABw+XFrQAoODpaHh4cyMzNd2jMzMxUWFlbuOmFhYZXqXxqO9uzZo2XLlp33OqG4uDgVFRVp9+7duvrqq8ss9/LyKjc4AQCAy49br0FyOByKiYlRamqqs62kpESpqamKj48vd534+HiX/pKUkpLi0r80HG3fvl1Lly5Vo0aNzlvLxo0bZbfbFRISUsW9AQAAlwu3n2JLSkrSoEGD1KlTJ8XGxmrq1KnKz8/XkCFDJEkDBw5Us2bNlJycLEkaPXq0unfvrilTpqh3796aO3eu1q1bpxkzZkg6E4769eun9PR0LVq0SMXFxc7rk4KCguRwOJSWlqbVq1frpptuUoMGDZSWlqbHHntMf/zjH9WwYUP3TAQAAKg13B6Q+vfvr0OHDmnixInKyMhQdHS0lixZ4rwQe+/evS4fJtelSxfNmTNHEyZM0Pjx49W6dWstXLhQ7dq1kyTt379fn3zyiSQpOjraZVvLly9Xjx495OXlpblz52ry5MkqKChQZGSkHnvsMZdrjAAAwG+X25+DVFfxHCQAAOqeOvEcJAAAgNqIgAQAAGDh9muQ4MoYo9zcXElSQEDAeT9tGAAAVD+OINUyubm5mrJog6Ys2uAMSgAAoGZxBKkWqu/bwN0lAADwm8YRJAAAAAsCEgAAgAUBCQAAwIKABAAAYEFAAgAAsCAgAQAAWBCQAAAALAhIAAAAFgQkAAAACwISAACABQEJAADAgoAEAABgQUACAACwICABAABYEJAAAAAsCEgAAAAWBCQAAAALAhIAAIAFAQkAAMCCgAQAAGBBQAIAALAgIAEAAFgQkAAAACwISAAAABYEJAAAAAsCEgAAgAUBCQAAwIKABAAAYEFAAgAAsCAgAQAAWBCQAAAALAhIAAAAFgQkAAAACwISAACABQEJAADAgoAEAABgQUACAACwICABAABYEJAAAAAsCEgAAAAWBCQAAAALAhIAAIAFAQkAAMCCgAQAAGBBQAIAALAgIAEAAFgQkAAAACwISAAAABYEJAAAAAsCEgAAgAUBCQAAwIKABAAAYEFAAgAAsCAgAQAAWBCQAAAALAhIAAAAFgQkAAAAi1oRkKZNm6aIiAh5e3srLi5Oa9asOWf/+fPnq02bNvL29lZUVJQWL17sXHb69Gk9/fTTioqKkq+vr5o2baqBAwfqwIEDLmNkZ2frvvvuk7+/vwIDAzV06FAdP378kuwfAACoW9wekObNm6ekpCRNmjRJ6enp6tChgxITE5WVlVVu/1WrVmnAgAEaOnSoNmzYoD59+qhPnz7asmWLJOnEiRNKT0/XM888o/T0dC1YsEDbtm3THXfc4TLOfffdp++//14pKSlatGiRvvrqKw0bNuyS7y8AAKj9bMYY484C4uLidP311+vNN9+UJJWUlCg8PFyjRo3S2LFjy/Tv37+/8vPztWjRImdb586dFR0drenTp5e7jbVr1yo2NlZ79uxRixYttHXrVrVt21Zr165Vp06dJElLlixRr1699Msvv6hp06bnrTsvL08BAQHKzc2Vv79/VXa9XDk5OXpr+Q5J0oibWikwMLDaxgYA4Leusr+/3XoEqbCwUOvXr1dCQoKzzW63KyEhQWlpaeWuk5aW5tJfkhITEyvsL0m5ubmy2WzOsJGWlqbAwEBnOJKkhIQE2e12rV69utwxCgoKlJeX5/ICAACXJ7cGpMOHD6u4uFihoaEu7aGhocrIyCh3nYyMjAvqf+rUKT399NMaMGCAMylmZGQoJCTEpZ+np6eCgoIqHCc5OVkBAQHOV3h4eKX2EQAA1D1uvwbpUjp9+rTuueceGWP09ttvX9RY48aNU25urvO1b9++aqoSAADUNp7u3HhwcLA8PDyUmZnp0p6ZmamwsLBy1wkLC6tU/9JwtGfPHi1btszlPGNYWFiZi8CLioqUnZ1d4Xa9vLzk5eVV6X0DAAB1l1uPIDkcDsXExCg1NdXZVlJSotTUVMXHx5e7Tnx8vEt/SUpJSXHpXxqOtm/frqVLl6pRo0ZlxsjJydH69eudbcuWLVNJSYni4uKqY9cAAEAd5tYjSJKUlJSkQYMGqVOnToqNjdXUqVOVn5+vIUOGSJIGDhyoZs2aKTk5WZI0evRode/eXVOmTFHv3r01d+5crVu3TjNmzJB0Jhz169dP6enpWrRokYqLi53XFQUFBcnhcOiaa67RrbfeqgcffFDTp0/X6dOnNXLkSN17772VuoMNAABc3twekPr3769Dhw5p4sSJysjIUHR0tJYsWeK8EHvv3r2y23890NWlSxfNmTNHEyZM0Pjx49W6dWstXLhQ7dq1kyTt379fn3zyiSQpOjraZVvLly9Xjx49JEnvv/++Ro4cqZ49e8put6tv3756/fXXL/0OAwCAWs/tz0Gqq3gOEgAAdU+deA4SAABAbURAAgAAsCAgAQAAWBCQAAAALAhIAAAAFgQkAAAACwISAACABQEJAADAgoAEAABgQUACAACwICABAABYEJAAAAAsCEgAAAAWBCQAAAALAhIAAIAFAQkAAMCCgAQAAGBBQAIAALAgIAEAAFgQkAAAACwISAAAABYEJAAAAAsCEgAAgAUBCQAAwIKABAAAYEFAAgAAsCAgAQAAWBCQAAAALAhIAAAAFgQkAAAACwISAACABQEJAADAgoAEAABgQUACAACwICABAABYEJAAAAAsCEgAAAAWBCQAAAALAhIAAIAFAQkAAMCCgAQAAGBBQAIAALAgIAEAAFgQkAAAACwISAAAABYEJAAAAAsCEgAAgAUBCQAAwIKABAAAYEFAAgAAsCAgAQAAWBCQAAAALAhIAAAAFgQkAAAACwISAACABQEJAADAgoAEAABgQUACAACwICABAABYEJAAAAAsCEgAAAAWbg9I06ZNU0REhLy9vRUXF6c1a9acs//8+fPVpk0beXt7KyoqSosXL3ZZvmDBAt1yyy1q1KiRbDabNm7cWGaMHj16yGazubweeuih6twtAABQh7k1IM2bN09JSUmaNGmS0tPT1aFDByUmJiorK6vc/qtWrdKAAQM0dOhQbdiwQX369FGfPn20ZcsWZ5/8/Hx17dpVL7300jm3/eCDD+rgwYPO18svv1yt+wYAAOoumzHGuGvjcXFxuv766/Xmm29KkkpKShQeHq5Ro0Zp7NixZfr3799f+fn5WrRokbOtc+fOio6O1vTp01367t69W5GRkdqwYYOio6NdlvXo0UPR0dGaOnVqlWvPy8tTQECAcnNz5e/vX+VxrHJycvTW8h2SpBE3tVJgYGC1jQ0AwG9dZX9/u+0IUmFhodavX6+EhIRfi7HblZCQoLS0tHLXSUtLc+kvSYmJiRX2P5f3339fwcHBateuncaNG6cTJ06cs39BQYHy8vJcXgAA4PLk6a4NHz58WMXFxQoNDXVpDw0N1Y8//ljuOhkZGeX2z8jIuKBt/8///I9atmyppk2bavPmzXr66ae1bds2LViwoMJ1kpOT9eyzz17QdgAAQN3ktoDkTsOGDXP+OSoqSk2aNFHPnj21c+dOXXnlleWuM27cOCUlJTm/zsvLU3h4+CWvFQAA1Dy3BaTg4GB5eHgoMzPTpT0zM1NhYWHlrhMWFnZB/SsrLi5OkrRjx44KA5KXl5e8vLwuajsAAKBucNs1SA6HQzExMUpNTXW2lZSUKDU1VfHx8eWuEx8f79JfklJSUirsX1mljwJo0qTJRY0DAAAuD249xZaUlKRBgwapU6dOio2N1dSpU5Wfn68hQ4ZIkgYOHKhmzZopOTlZkjR69Gh1795dU6ZMUe/evTV37lytW7dOM2bMcI6ZnZ2tvXv36sCBA5Kkbdu2STpz9CksLEw7d+7UnDlz1KtXLzVq1EibN2/WY489phtvvFHt27ev4RkAAAC1kVsDUv/+/XXo0CFNnDhRGRkZio6O1pIlS5wXYu/du1d2+68Hubp06aI5c+ZowoQJGj9+vFq3bq2FCxeqXbt2zj6ffPKJM2BJ0r333itJmjRpkiZPniyHw6GlS5c6w1h4eLj69u2rCRMm1NBeAwCA2s6tz0Gqy3gOEgAAdU+tfw4SAABAbUVAAgAAsCAgAQAAWFQpIP3888/VXQcAAECtUaWA1KpVK910003617/+pVOnTlV3TQAAAG5VpYCUnp6u9u3bKykpSWFhYRo+fLjWrFlT3bUBAAC4RZUCUnR0tF577TUdOHBA//jHP3Tw4EF17dpV7dq106uvvqpDhw5Vd50AAAA15qIu0vb09NTdd9+t+fPn66WXXtKOHTv0xBNPKDw8XAMHDtTBgwerq04AAIAac1EBad26dRoxYoSaNGmiV199VU888YR27typlJQUHThwQHfeeWd11QkAAFBjqvRRI6+++qpmzpypbdu2qVevXpo9e7Z69erl/FiQyMhIzZo1SxEREdVZKwAAQI2oUkB6++23df/992vw4MFq0qRJuX1CQkL097///aKKAwAAcIcqBaSUlBS1aNHC5YNkJckYo3379qlFixZyOBwaNGhQtRQJAABQk6p0DdKVV16pw4cPl2nPzs5WZGTkRRcFAADgTlUKSMaYctuPHz8ub2/viyoIAADA3S7oFFtSUpIkyWazaeLEifLx8XEuKy4u1urVqxUdHV2tBQIAANS0CwpIGzZskHTmCNJ3330nh8PhXOZwONShQwc98cQT1VshAABADbuggLR8+XJJ0pAhQ/Taa6/J39//khQFAADgTlW6i23mzJnVXQcAAECtUemAdPfdd2vWrFny9/fX3Xfffc6+CxYsuOjCAAAA3KXSASkgIEA2m835ZwAAgMtVpQPS2afVOMUGAAAuZ1V6DtLJkyd14sQJ59d79uzR1KlT9cUXX1RbYQAAAO5SpYB05513avbs2ZKknJwcxcbGasqUKbrzzjv19ttvV2uBAAAANa1KASk9PV3dunWTJH344YcKCwvTnj17NHv2bL3++uvVWiAAAEBNq1JAOnHihBo0aCBJ+uKLL3T33XfLbrerc+fO2rNnT7UWCAAAUNOqFJBatWqlhQsXat++ffr88891yy23SJKysrJ4eCQAAKjzqhSQJk6cqCeeeEIRERGKi4tTfHy8pDNHk6677rpqLRAAAKCmVelJ2v369VPXrl118OBBdejQwdnes2dP3XXXXdVWHAAAgDtUKSBJUlhYmMLCwlzaYmNjL7ogAAAAd6tSQMrPz9eLL76o1NRUZWVlqaSkxGX5zz//XC3FAQAAuEOVAtIDDzygFStW6E9/+pOaNGni/AgSAACAy0GVAtJnn32mTz/9VDfccEN11wMAAOB2VbqLrWHDhgoKCqruWgAAAGqFKgWk5557ThMnTnT5PDYAAIDLRZVOsU2ZMkU7d+5UaGioIiIiVK9ePZfl6enp1VIcAACAO1QpIPXp06eaywAAAKg9qhSQJk2aVN11AAAA1BpVugZJknJycvTuu+9q3Lhxys7OlnTm1Nr+/furrTgAAAB3qNIRpM2bNyshIUEBAQHavXu3HnzwQQUFBWnBggXau3evZs+eXd11AgAA1JgqHUFKSkrS4MGDtX37dnl7ezvbe/Xqpa+++qraigMAAHCHKgWktWvXavjw4WXamzVrpoyMjIsuCgAAwJ2qFJC8vLyUl5dXpv2nn35S48aNL7ooAAAAd6pSQLrjjjv0l7/8RadPn5Yk2Ww27d27V08//bT69u1brQUCAADUtCoFpClTpuj48eNq3LixTp48qe7du6tVq1Zq0KCB/vrXv1Z3jQAAADWqSnexBQQEKCUlRStXrtSmTZt0/PhxdezYUQkJCdVdHwAAQI274IBUUlKiWbNmacGCBdq9e7dsNpsiIyMVFhYmY4xsNtulqBMAAKDGXNApNmOM7rjjDj3wwAPav3+/oqKidO2112rPnj0aPHiw7rrrrktVJwAAQI25oCNIs2bN0ldffaXU1FTddNNNLsuWLVumPn36aPbs2Ro4cGC1FgkAAFCTLugI0gcffKDx48eXCUeS9Lvf/U5jx47V+++/X23FAQAAuMMFBaTNmzfr1ltvrXD5bbfdpk2bNl10UQAAAO50QQEpOztboaGhFS4PDQ3V0aNHL7ooAAAAd7qggFRcXCxPz4ovW/Lw8FBRUdFFFwUAAOBOF3SRtjFGgwcPlpeXV7nLCwoKqqUonJnr3NxcBQQE8OgEAABq2AUFpEGDBp23D3ewVY9TJ45rysd79JeBAQoMDHR3OQAA/KZcUECaOXPmpaoD5fD28XV3CQAA/CZV6bPYAAAALmcEJAAAAAsCEgAAgAUBCQAAwIKABAAAYEFAAgAAsCAgAQAAWLg9IE2bNk0RERHy9vZWXFyc1qxZc87+8+fPV5s2beTt7a2oqCgtXrzYZfmCBQt0yy23qFGjRrLZbNq4cWOZMU6dOqVHHnlEjRo1kp+fn/r27avMzMzq3C0AAFCHuTUgzZs3T0lJSZo0aZLS09PVoUMHJSYmKisrq9z+q1at0oABAzR06FBt2LBBffr0UZ8+fbRlyxZnn/z8fHXt2lUvvfRShdt97LHH9H//93+aP3++VqxYoQMHDujuu++u9v0DAAB1k80YY9y18bi4OF1//fV68803JUklJSUKDw/XqFGjNHbs2DL9+/fvr/z8fC1atMjZ1rlzZ0VHR2v69OkufXfv3q3IyEht2LBB0dHRzvbc3Fw1btxYc+bMUb9+/SRJP/74o6655hqlpaWpc+fO5dZaUFDg8llzeXl5Cg8PV25urvz9/as8B1Y5OTl6a/kOncw/poJTpzS+XzwfNQIAQDXJy8tTQEDAeX9/u+0IUmFhodavX6+EhIRfi7HblZCQoLS0tHLXSUtLc+kvSYmJiRX2L8/69et1+vRpl3HatGmjFi1anHOc5ORkBQQEOF/h4eGV3iYAAKhb3BaQDh8+rOLiYoWGhrq0h4aGKiMjo9x1MjIyLqh/RWM4HI4yR2XON864ceOUm5vrfO3bt6/S2wQAAHXLBX1Y7W+Zl5eXvLy83F0GAACoAW47ghQcHCwPD48yd49lZmYqLCys3HXCwsIuqH9FYxQWFionJ+eixgEAAJcvtwUkh8OhmJgYpaamOttKSkqUmpqq+Pj4cteJj4936S9JKSkpFfYvT0xMjOrVq+cyzrZt27R3794LGgcAAFy+3HqKLSkpSYMGDVKnTp0UGxurqVOnKj8/X0OGDJEkDRw4UM2aNVNycrIkafTo0erevbumTJmi3r17a+7cuVq3bp1mzJjhHDM7O1t79+7VgQMHJJ0JP9KZI0dhYWEKCAjQ0KFDlZSUpKCgIPn7+2vUqFGKj4+v8A42AADw2+LWgNS/f38dOnRIEydOVEZGhqKjo7VkyRLnhdh79+6V3f7rQa4uXbpozpw5mjBhgsaPH6/WrVtr4cKFateunbPPJ5984gxYknTvvfdKkiZNmqTJkydLkv72t7/Jbrerb9++KigoUGJiot56660a2GMAAFAXuPU5SHVZZZ+jcKF4DhIAAJdOrX8OEgAAQG1FQAIAALAgIAEAAFgQkAAAACwISAAAABYEJAAAAAsCEgAAgAUBqRYzxig3N1c8qgoAgJpFQKrFCk7ma8rHa5Wbm+vuUgAA+E0hINVy3j6+7i4BAIDfHAISAACABQEJAADAgoAEAABgQUACAACwICABAABYEJAAAAAsCEgAAAAWBCQAAAALAhIAAIAFAQkAAMCCgAQAAGBBQAIAALAgIAEAAFgQkAAAACwISAAAABYEJAAAAAsCEgAAgAUBCQAAwIKABAAAYEFAAgAAsCAgAQAAWBCQAAAALAhIAAAAFgQkAAAACwISAACABQEJAADAgoAEAABgQUACAACwICABAABYEJAAAAAsCEgAAAAWBCQAAAALAhIAAIAFAQkAAMCCgAQAAGBBQAIAALAgIAEAAFgQkAAAACwISAAAABYEJAAAAAsCEgAAgAUBCQAAwIKABAAAYEFAAgAAsCAgAQAAWBCQAAAALAhIAAAAFgQkAAAACwISAACABQEJAADAgoAEAABgUSsC0rRp0xQRESFvb2/FxcVpzZo15+w/f/58tWnTRt7e3oqKitLixYtdlhtjNHHiRDVp0kT169dXQkKCtm/f7tInIiJCNpvN5fXiiy9W+74BAIC6x+0Bad68eUpKStKkSZOUnp6uDh06KDExUVlZWeX2X7VqlQYMGKChQ4dqw4YN6tOnj/r06aMtW7Y4+7z88st6/fXXNX36dK1evVq+vr5KTEzUqVOnXMb6y1/+ooMHDzpfo0aNuqT7CgAA6ga3B6RXX31VDz74oIYMGaK2bdtq+vTp8vHx0T/+8Y9y+7/22mu69dZb9eSTT+qaa67Rc889p44dO+rNN9+UdObo0dSpUzVhwgTdeeedat++vWbPnq0DBw5o4cKFLmM1aNBAYWFhzpevr++l3l0AAFAHuDUgFRYWav369UpISHC22e12JSQkKC0trdx10tLSXPpLUmJiorP/rl27lJGR4dInICBAcXFxZcZ88cUX1ahRI1133XV65ZVXVFRUVGGtBQUFysvLc3nVBGOMcnNzZYypke0BAAA3B6TDhw+ruLhYoaGhLu2hoaHKyMgod52MjIxz9i/9//nGfPTRRzV37lwtX75cw4cP1wsvvKCnnnqqwlqTk5MVEBDgfIWHh1d+Ry9Cwcl8Tfl4rXJzc2tkewAAQPJ0dwHukpSU5Pxz+/bt5XA4NHz4cCUnJ8vLy6tM/3Hjxrmsk5eXV2MhyduHU38AANQktx5BCg4OloeHhzIzM13aMzMzFRYWVu46YWFh5+xf+v8LGVOS4uLiVFRUpN27d5e73MvLS/7+/i4vAABweXJrQHI4HIqJiVFqaqqzraSkRKmpqYqPjy93nfj4eJf+kpSSkuLsHxkZqbCwMJc+eXl5Wr16dYVjStLGjRtlt9sVEhJyMbsEAAAuA24/xZaUlKRBgwapU6dOio2N1dSpU5Wfn68hQ4ZIkgYOHKhmzZopOTlZkjR69Gh1795dU6ZMUe/evTV37lytW7dOM2bMkCTZbDaNGTNGzz//vFq3bq3IyEg988wzatq0qfr06SPpzIXeq1ev1k033aQGDRooLS1Njz32mP74xz+qYcOGbpkHAABQe7g9IPXv31+HDh3SxIkTlZGRoejoaC1ZssR5kfXevXtlt/96oKtLly6aM2eOJkyYoPHjx6t169ZauHCh2rVr5+zz1FNPKT8/X8OGDVNOTo66du2qJUuWyNvbW9KZ02Vz587V5MmTVVBQoMjISD322GMu1xgBAIDfLpvh/vEqycvLU0BAgHJzc6v1eqScnBy9tXyHTuYfU272YUmSt4+fxveLV2BgYLVtBwCA36LK/v52+4MiAQAAahsCEgAAgAUBCQAAwIKABAAAYEFAAgAAsCAgAQAAWBCQAAAALAhIAAAAFgQkAAAACwISAACABQEJAADAgoAEAABgQUACAACwICABAABYeLq7AJTv6KkSrTniJT/PEjUzRoVFJe4uCQCA3wyOINVCeaeKtHT3KWUVeOjn/Hr6+qDRA3O2EJIAAKghBKRa5tDxQn36Y45OFUn+niVq6VMkT5u0+cAxvbNip7vLAwDgN4GAVIsUFpXokXnf61hBsRo4bOrc6JQ6BBaqY+Mzy99YtkM7so65t0gAAH4DCEi1iMPTrntimsi3nl09I7zk7XGmPdTjhEK8ilVYXKKnPtyskhLj3kIBALjMEZBqmX7RYbqnQ7AaOH791thsUmyYp3wcdqXvzdGK7YfcWCEAAJc/AlItVM/DVqbNp55NfdqHSpLmrN5b0yUBAPCbQkCqQ/pFh0mSlv2YpYzcU26uBgCAyxcBqQ65IthHsZFBKi4xmrd2n7vLAQDgskVAqmPui2shSZq7dq+KinkuEgAAlwIBqY65tV2YgnwdOph7Sit+4mJtAAAuBQJSHePl6aG7rmsmSfpk0wE3VwMAwOWJgFQH/b59E0nS0h8ydep0sZurAQDg8kNAqoOiwwPVLLC+8guL9eU2TrMBAFDdCEh1kM1mU6+oM7f8L/7uoJurAQDg8kNAqqN6t28qSVq6ldNsAABUNwJSHdWheYCaBdbXicJifbkty93lAABwWSEg1VE2m029/3ux9qffZbi5GgAALi8EpDqsV9SZgJTKaTYAAKoVAamOMMYoNzdXOTk5MsZI4jQbAACXCgGpjig4ma9pS7dqyqINys3NleR6mm3RZu5mAwCguhCQ6hBvHz/V923g0tbbeZotSycLOc0GAEB1ICDVce2bB6h5w/o6eZrTbAAAVBcCUh1ljFFOTo6kX48iLeKhkQAAVAsCUh2Vm5urv877Srm5uc7rkFK3Zup4QZGbKwMAoO4jINUxpXezGWPk7eMnSYpqFqDIYF+dOl2iJVt4JhIAABeLgFTHnDpxXFM+Xqu8vDxnWJKku65rJkn6aMMv7iwPAIDLAgGpDvL28ZUkFZzI15SP1yo3N9cZkFbtPKKDuSfdWR4AAHUeAamOKw1L4UE+io0IkjHSwg0H3FwVAAB1GwHpMnJ3xzNHkRak/+J82jYAALhwBKQ66Ndrj1xDUK/2TeTwtGt71nFt+iXXPcUBAHAZICDVQQUn8zVt8QYVFBa6tPt719Pv//tMpFkrd7mjNAAALgsEpDrKy8en3PYhN0RKOvPZbBm5p2qyJAAALhsEpMtMVPMAxUYEqajE6J/f7nZ3OQAA1EkEpMvQ/V0jJElzVu/lA2wBAKgCAtJl6Oa2YWresL6Onjit+ev3ubscAADqHALSZcjDbtOwG6+QJL22dLvyTp12c0UAANQtBKTLiDFGOTk5MsZoQGwLXdHYV0fyCzVt2Q53lwYAQJ1CQLqM5Obm6q/zvlJubq7qedg1ofc1kqSZK3drz5F8N1cHAEDdQUC6TJQ+PLL0o0ck6aarQ9StdbAKi0v0zMffq6SEp2sDAFAZBKQ6rjQY7d27V/9vwUoVFPz68EibzaaJv28rL0+7vvrpkN7gVBsAAJVCQKrjCk7ma9rSrXpzyWbZPOqVWd46tIH+eleUJGlq6k9avi2rpksEAKDOISBdBrx9/OTt6yfp1yNKZ39Ybb+Y5vqfuBYyRho1Z4NW7TjsrlIBAKgTCEiXmYKT+Zry8dr/fpjtrybd3ladrwjS8YIiDZq5Rh9v3O+mCgEAqP0ISJchr/o+ys3N1dGjR3X06FEZY+Tl6aFZQ2LVKypMp4uNRs/dqDFzNygrr/zPayt9ZEDpYwMAAPgt8XR3Aah+pdclmaLTKigo0F8GJigwMFDe9Tz0xoCOCq6/UbPX7NfCjQe0dGuW/ieuhe69PlxXNPZzjpGbm6spizZIkh7//XUKDAx0094AAFDzCEiXKW8fP5ni05LdQ7m5uQoICJDNZpOH3aak30Xq0OEj2nuynr4/eFwzvvpZM776We2a+atb68aKjWgov+Jj8vbxlc1W+w8yll53VbqPAABcrFrx22/atGmKiIiQt7e34uLitGbNmnP2nz9/vtq0aSNvb29FRUVp8eLFLsuNMZo4caKaNGmi+vXrKyEhQdu3b3fpk52drfvuu0/+/v4KDAzU0KFDdfz48WrfN3crvSbJerqskbdNb9zRQn+762p1u7Kh7DZpy/48vf3lTg2ZtU5/+Oc2zVp3SB9/n60JH/+gN5dt13/W/6KVOw5r56Hjyi8ocnlyt6QKv77Up+nOfkCmlbUmAAAqw+1HkObNm6ekpCRNnz5dcXFxmjp1qhITE7Vt2zaFhISU6b9q1SoNGDBAycnJ+v3vf685c+aoT58+Sk9PV7t27SRJL7/8sl5//XW99957ioyM1DPPPKPExET98MMP8vb2liTdd999OnjwoFJSUnT69GkNGTJEw4YN05w5c2p0/2uCV30f7du3T7NX7dKo26IlSQUnjuuleV9Jknwk9Y4I0ZFCD/n5+uinQ6e05+gpnS6xKfP4aS3aelSLth4tM66fl4fsJUVqHRaghj71VN+jRNv3H1HvmCvULDhADnNan67fKYeHdP8Nkbr6ipbyqudx3qM8VTki5O3jV257aXj6c/8bOU0IAKg0m3HzP63j4uJ0/fXX680335QklZSUKDw8XKNGjdLYsWPL9O/fv7/y8/O1aNEiZ1vnzp0VHR2t6dOnyxijpk2b6vHHH9cTTzwh6cwvydDQUM2aNUv33nuvtm7dqrZt22rt2rXq1KmTJGnJkiXq1auXfvnlFzVt2vS8defl5SkgIEC5ubny9/evjqmQJOXk5Oit5Tt0Mv+YcrNdb8cPbNxEpvh0pdqtbQUnTsjLx0fevg3+e23SqXLHyPplryTJs76P7A1CdPREobJy8nWy2KaQRgHKLZAO5J7UicKSKu2fh90mX4eH/Lw85ePlKYdd8nZ4ysNuk0pK5GG3ycMu/ZxxVG2aNZLDUU822WS3SzbZJNuZw56ni07Lq55DdrtNpwsL9cMv2WrXopG8vRxyeNplLylSoJ+PbCWnterHA+p1XUsFBfipfj0P1Xd4qH49D3nX85B3Pbvqedjl8Pz1/w6PMy+7/dKfrisNg5I4RQgANaCyv7/degSpsLBQ69ev17hx45xtdrtdCQkJSktLK3edtLQ0JSUlubQlJiZq4cKFkqRdu3YpIyNDCQkJzuUBAQGKi4tTWlqa7r33XqWlpSkwMNAZjiQpISFBdrtdq1ev1l133VVmuwUFBSooKHB+XfpLLS8v78J3/Bzy8vKUczhDp/LzdSzH9aiNzW6XKSqqVHt5bYWnTp53jMJTJ519/T3sCioqUr2i//Y9ckCP39xBc9dk6Hj+cWXn5cvTr5E6X9VEK3fnKf9koY6fLFChsalZ4yDlFRTrYF6hCopKVGzO/OIvkZRzUsqpxFzsP/pL5Sbtv3ZkHatw2eo9my9oLEnytNvk6XEmsNl05snkNsn5UunXNjn//98llVZSUqL8wiJJkq/Dswqh7Nf+Z2crWzldbBXUVt56Zwc1W5k/nN3v7DabS9u5aih3m+UUVf52yl2hTL8z//Qzpf8528yvC2VKX0Yypb1M2bZf19Ov6xnj7Hd22faz3xcuX9tkd75XbM7l0n/bbWfmpzoicm07oWyqoaLq+qd8dQxTfYcVqmEgU+4fXWo05TS69C13nfIHPl9fY8qs4sL6M20r5++w0hYPDw9Nur2tOrYMqmC0qin9vX2+40NuDUiHDx9WcXGxQkNDXdpDQ0P1448/lrtORkZGuf0zMjKcy0vbztXHevrO09NTQUFBzj5WycnJevbZZ8u0h4eHV7R7l6VZk8u2/aecfusvdSEAgMvel3++dGMfO3ZMAQEBFS53+zVIdcW4ceNcjlyVlJQoOztbjRo1qtbTInl5eQoPD9e+ffuq9dQdfsUcX3rM8aXHHNcM5vnSq+k5Nsbo2LFj572cxq0BKTg4WB4eHsrMzHRpz8zMVFhYWLnrhIWFnbN/6f8zMzPVpEkTlz7R0dHOPllZrp9JVlRUpOzs7Aq36+XlJS8vL5e2S3nRr7+/Pz+MlxhzfOkxx5cec1wzmOdLrybn+FxHjkq59TZ/h8OhmJgYpaamOttKSkqUmpqq+Pj4cteJj4936S9JKSkpzv6RkZEKCwtz6ZOXl6fVq1c7+8THxysnJ0fr1/96ImjZsmUqKSlRXFxcte0fAACom9x+ii0pKUmDBg1Sp06dFBsbq6lTpyo/P19DhgyRJA0cOFDNmjVTcnKyJGn06NHq3r27pkyZot69e2vu3Llat26dZsyYIenMxY9jxozR888/r9atWztv82/atKn69OkjSbrmmmt066236sEHH9T06dN1+vRpjRw5Uvfee2+l7mADAACXN7cHpP79++vQoUOaOHGiMjIyFB0drSVLljgvst67d6/s9l8PdHXp0kVz5szRhAkTNH78eLVu3VoLFy50PgNJkp566inl5+dr2LBhysnJUdeuXbVkyRLnM5Ak6f3339fIkSPVs2dP2e129e3bV6+//nrN7XgFvLy8NGnSpDKn81B9mONLjzm+9JjjmsE8X3q1dY7d/hwkAACA2qZWfNQIAABAbUJAAgAAsCAgAQAAWBCQAAAALAhIAAAAFgSkWmbatGmKiIiQt7e34uLitGbNGneXVCt99dVXuv3229W0aVPZbDbnhxWXMsZo4sSJatKkierXr6+EhARt377dpU92drbuu+8++fv7KzAwUEOHDtXx48dd+mzevFndunWTt7e3wsPD9fLLL1/qXas1kpOTdf3116tBgwYKCQlRnz59tG3bNpc+p06d0iOPPKJGjRrJz89Pffv2LfOk+71796p3797y8fFRSEiInnzySRUVFbn0+fLLL9WxY0d5eXmpVatWmjVr1qXevVrh7bffVvv27Z1PEI6Pj9dnn33mXM78Vr8XX3zR+by8UszzxZk8efJ/P4D511ebNm2cy+vs/BrUGnPnzjUOh8P84x//MN9//7158MEHTWBgoMnMzHR3abXO4sWLzZ///GezYMECI8l89NFHLstffPFFExAQYBYuXGg2bdpk7rjjDhMZGWlOnjzp7HPrrbeaDh06mG+//dZ8/fXXplWrVmbAgAHO5bm5uSY0NNTcd999ZsuWLeaDDz4w9evXN++8805N7aZbJSYmmpkzZ5otW7aYjRs3ml69epkWLVqY48ePO/s89NBDJjw83KSmppp169aZzp07my5dujiXFxUVmXbt2pmEhASzYcMGs3jxYhMcHGzGjRvn7PPzzz8bHx8fk5SUZH744QfzxhtvGA8PD7NkyZIa3V93+OSTT8ynn35qfvrpJ7Nt2zYzfvx4U69ePbNlyxZjDPNb3dasWWMiIiJM+/btzejRo53tzPPFmTRpkrn22mvNwYMHna9Dhw45l9fV+SUg1SKxsbHmkUcecX5dXFxsmjZtapKTk91YVe1nDUglJSUmLCzMvPLKK862nJwc4+XlZT744ANjjDE//PCDkWTWrl3r7PPZZ58Zm81m9u/fb4wx5q233jINGzY0BQUFzj5PP/20ufrqqy/xHtVOWVlZRpJZsWKFMebMnNarV8/Mnz/f2Wfr1q1GkklLSzPGnAmydrvdZGRkOPu8/fbbxt/f3zmvTz31lLn22mtdttW/f3+TmJh4qXepVmrYsKF59913md9qduzYMdO6dWuTkpJiunfv7gxIzPPFmzRpkunQoUO5y+ry/HKKrZYoLCzU+vXrlZCQ4Gyz2+1KSEhQWlqaGyure3bt2qWMjAyXuQwICFBcXJxzLtPS0hQYGKhOnTo5+yQkJMhut2v16tXOPjfeeKMcDoezT2JiorZt26ajR4/W0N7UHrm5uZKkoKAgSdL69et1+vRpl3lu06aNWrRo4TLPUVFRzifjS2fmMC8vT99//72zz9ljlPb5rb3vi4uLNXfuXOXn5ys+Pp75rWaPPPKIevfuXWYumOfqsX37djVt2lRXXHGF7rvvPu3du1dS3Z5fAlItcfjwYRUXF7u8QSQpNDRUGRkZbqqqbiqdr3PNZUZGhkJCQlyWe3p6KigoyKVPeWOcvY3fipKSEo0ZM0Y33HCD82N9MjIy5HA4FBgY6NLXOs/nm8OK+uTl5enkyZOXYndqle+++05+fn7y8vLSQw89pI8++kht27ZlfqvR3LlzlZ6e7vxMz7MxzxcvLi5Os2bN0pIlS/T2229r165d6tatm44dO1an59ftn8UGoPZ75JFHtGXLFn3zzTfuLuWyc/XVV2vjxo3Kzc3Vhx9+qEGDBmnFihXuLuuysW/fPo0ePVopKSkun8eJ6nPbbbc5/9y+fXvFxcWpZcuW+ve//6369eu7sbKLwxGkWiI4OFgeHh5lruzPzMxUWFiYm6qqm0rn61xzGRYWpqysLJflRUVFys7OdulT3hhnb+O3YOTIkVq0aJGWL1+u5s2bO9vDwsJUWFionJwcl/7WeT7fHFbUx9/fv07/5VpZDodDrVq1UkxMjJKTk9WhQwe99tprzG81Wb9+vbKystSxY0d5enrK09NTK1as0Ouvvy5PT0+FhoYyz9UsMDBQV111lXbs2FGn38cEpFrC4XAoJiZGqampzraSkhKlpqYqPj7ejZXVPZGRkQoLC3OZy7y8PK1evdo5l/Hx8crJydH69eudfZYtW6aSkhLFxcU5+3z11Vc6ffq0s09KSoquvvpqNWzYsIb2xn2MMRo5cqQ++ugjLVu2TJGRkS7LY2JiVK9ePZd53rZtm/bu3esyz999951LGE1JSZG/v7/atm3r7HP2GKV9fqvv+5KSEhUUFDC/1aRnz5767rvvtHHjRuerU6dOuu+++5x/Zp6r1/Hjx7Vz5041adKkbr+PL9nl37hgc+fONV5eXmbWrFnmhx9+MMOGDTOBgYEuV/bjjGPHjpkNGzaYDRs2GEnm1VdfNRs2bDB79uwxxpy5zT8wMNB8/PHHZvPmzebOO+8s9zb/6667zqxevdp88803pnXr1i63+efk5JjQ0FDzpz/9yWzZssXMnTvX+Pj4/GZu83/44YdNQECA+fLLL11u3z1x4oSzz0MPPWRatGhhli1bZtatW2fi4+NNfHy8c3np7bu33HKL2bhxo1myZIlp3LhxubfvPvnkk2br1q1m2rRpv5nbo8eOHWtWrFhhdu3aZTZv3mzGjh1rbDab+eKLL4wxzO+lcvZdbMYwzxfr8ccfN19++aXZtWuXWblypUlISDDBwcEmKyvLGFN355eAVMu88cYbpkWLFsbhcJjY2Fjz7bffurukWmn58uVGUpnXoEGDjDFnbvV/5plnTGhoqPHy8jI9e/Y027ZtcxnjyJEjZsCAAcbPz8/4+/ubIUOGmGPHjrn02bRpk+natavx8vIyzZo1My+++GJN7aLblTe/kszMmTOdfU6ePGlGjBhhGjZsaHx8fMxdd91lDh486DLO7t27zW233Wbq169vgoODzeOPP25Onz7t0mf58uUmOjraOBwOc8UVV7hs43J2//33m5YtWxqHw2EaN25sevbs6QxHxjC/l4o1IDHPF6d///6mSZMmxuFwmGbNmpn+/fubHTt2OJfX1fm1GWPMpTs+BQAAUPdwDRIAAIAFAQkAAMCCgAQAAGBBQAIAALAgIAEAAFgQkAAAACwISAAAABYEJAAAAAsCEgAAgAUBCQAAwIKABAAAYPH/Ae9uAN2TCrCNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"Description\"], df[\"Social\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "text_lengths = [len(t.split()) for t in train_texts]\n",
    "ax = sns.histplot(data=text_lengths, kde=True, stat=\"density\")\n",
    "ax.set_title(\"Texts length distribution (number of words)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Subjective', 'Gender', 'Jargon', 'Social']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# credit: https://github.com/NielsRogge/Transformers-Tutorials\n",
    "labels = [label for label in dataset[\"train\"].features.keys() if label not in [\"ObjectID\", \"Description\"]]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# credit: https://github.com/NielsRogge/Transformers-Tutorials\n",
    "def preprocess_data(data):\n",
    "\n",
    "\t# save the given batch of descs\n",
    "\tdescs = data[\"Description\"]\n",
    "\n",
    "\t# encode them using bert tokenizer\n",
    "\tencoding = tokenizer(descs, padding=True, truncation=True, max_length=512)#.to(\"mps\")\n",
    "\n",
    "\t# create numpy array (no need to convert T/F to 0/1 since we annotated that way)\n",
    "\t# MATRIX FORMAT:\n",
    "\t# |---------------------------------\n",
    "\t# | bias   | bias1 bias2 bias3 bias4\n",
    "\t# |--------+------------------------\n",
    "\t# | desc0  |   1     0     1     0\n",
    "\t# | desc1  |   0     1     0     1\n",
    "\t# | desc2  |   0     1     0     0\n",
    "\t# | ...    |  ...   ...   ...   ...\n",
    "\t# \n",
    "\t# Convert integers to float and data to an NDarray\n",
    "\tsubjective = np.array(data[\"Subjective\"], dtype=float)\n",
    "\tgender = np.array(data[\"Gender\"], dtype=float)\n",
    "\tjargon = np.array(data[\"Jargon\"], dtype=float)\n",
    "\tsocial = np.array(data[\"Social\"], dtype=float)\n",
    "\t# Stack the arrays column-wise to form a 2D array (matrix)\n",
    "\tlabels_matrix = np.stack((subjective, gender, jargon, social), axis=1)\n",
    "\n",
    "\t\n",
    "\t# # Credit ChatGPT\n",
    "\t# # Validate the data stacking by comparing 3 random indices\n",
    "\t# import random\n",
    "\t# for _ in range(3):\n",
    "\t# \tidx = random.randint(0, len(subjective) - 1)\n",
    "\t# \tdataset_labels = [data[\"Subjective\"][idx], data[\"Gender\"][idx], data[\"Jargon\"][idx], data[\"Social\"][idx]]\n",
    "\t# \tmatrix_labels = labels_matrix[idx].tolist()\n",
    "\t# \tassert dataset_labels == matrix_labels, f\"Mismatch at index {idx}: {dataset_labels} != {matrix_labels}\"\n",
    "\t# \tprint(f\"Index {idx} matches: {dataset_labels}\")\n",
    "\n",
    "\n",
    "\t# FORMAT OF var encoding of type BatchEncoding (the length of the vals of each key \n",
    "\t# equal the num of descs/objects in given batch):\n",
    "\t# input_ids: [101, 1030, 4748, 7229, 1035, ...], ...\n",
    "\t# token_type_ids: [0, 0, 0, 0, 0, ...], ...\n",
    "\t# attention_mask: [1, 1, 1, 1, 1, ...], ...\n",
    "\t# labels: [1.0, 1.0, 0.0, 0.0], ...\n",
    "\tencoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "\treturn encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe8b5452fa44808bfe45d25bf53d61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3fa6e8d2024be0bb6e909ac0e2084d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b590c1f34b2e4ebb9d266e6b2dbbdabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] sprinkler flask provenance taken from purchase document 3 ( see accession lot ). provenance taken from purchase document 3 ( see accession lot ). purchased by georges ricard february 28, 1974 from raynaud and gamet auctions, marseille, lot # 258. expert : laporte. catalogue description : “ flacon d ’ athlete en verre a panse ornee en relief de torsades. rome, ier - iv eme siecles ad. hauteur 10 cms. ” senusret purchase reference no. 3. ex coll. musee de l'egypte et le monde antique, collection sanousrit, monaco, 1975 - 1982. ex coll. georges ricard foundation, santa barbara, california. purchased by georges ricard february 28, 1974 from raynaud and gamet auctions, marseille, lot # 258. expert : laporte. catalogue description : “ flacon d ’ athlete en verre a panse ornee en relief de torsades. rome, ier - iv eme siecles ad. hauteur 10 cms. ” senusret purchase reference no. 3. ex coll. musee de l'egypte et le monde antique, collection sanousrit, monaco, 1975 - 1982. ex coll. georges ricard foundation, santa barbara, california. this glass sprinkler is blown from transparent olive green glass. beneath the perfectly symmetrical horizontal rim, a straight neck meets the body with a constriction and a diaphragm. the subtle spiral ribbing on the spherical body was achieved by pattern blowing. the bottom is flat and smooth with a faint pontil mark. syria, eastern roman empire, late third to early fourth century ad. “ most sprinklers with this type of surface pattern probably date from the late third and early fourth centuries … such sprinklers were made in more than one workshop, but probably not over a long period of time, because relatively few have been preserved … expanded mold - blown ribs created in a one - piece conical mold [ is ] a technique that is not common with sprinklers ” ( stern, 2001 : 153 ). < b > parallel : < / b > “ sprinkler flask. yellow - green glass. this flask made out of a thick glass fabric has a spherical body decorated with swirling horizontal ribs. the tubular neck flares out to a wide horizontal infolded rim. at the [SEP]\n",
      "[0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# see example\n",
    "print(tokenizer.decode(encoded_dataset[\"train\"][0][\"input_ids\"]))\n",
    "print(encoded_dataset[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset a standard torch dataset by converting to tensors (and more?)\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add Warmup?\n",
    "Experiment with learning rate\n",
    "experiment with batch size\n",
    "experient with gradient_accumulation_steps\n",
    "another metric?\n",
    "Choose another optimizer: RMSprop, SGD...\n",
    "Increase the learning rate by default and then use the callback ReduceLROnPlateau\n",
    "\"\"\"\n",
    "# use keras instead of huggung face to make it easier to work with messing with layers\n",
    "# remove entries greater than 512 words to remove noise\n",
    "# enchance data by repeatung key terms\n",
    "# cut 512 from middle of the dataset\n",
    "# try giving it only the labels with 5 word context\n",
    "# try doing subtext technique to give it 1000 words\n",
    "\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "num_epochs = 30\n",
    "batch_size = 8\n",
    "lr = 2e-5\n",
    "metric_name = \"f1\"\n",
    "decay = 0.01\n",
    "\n",
    "model_path = \"./model\"\n",
    "tokenizer_path = \"./tokenizer\"\n",
    "logs_path = \"./logs\"\n",
    "\n",
    "with open('../../../hg_token.txt', 'r') as file:\n",
    "\thg_token = file.read()\n",
    "\n",
    "\n",
    "# args for training the model\n",
    "# save the model every epoch and choose the best performing epoch as the final version of the model\n",
    "args = TrainingArguments(\n",
    "\teval_strategy = \"epoch\",\n",
    "\tsave_strategy = \"epoch\",\n",
    "    # save_total_limit = 5,\n",
    "\tlogging_strategy = \"epoch\",\n",
    "\tlearning_rate = lr,\n",
    "\tper_device_train_batch_size = batch_size,\n",
    "\tper_device_eval_batch_size = batch_size,\n",
    "\tnum_train_epochs = num_epochs,\n",
    "\tweight_decay = decay,\n",
    "\tload_best_model_at_end = True,\n",
    "\tmetric_for_best_model = metric_name,\n",
    "\tlogging_dir = logs_path,\n",
    "\toutput_dir = model_path,\n",
    "    warmup_steps=100,\n",
    "\t# use_mps_device = True,\n",
    "\t# use_cpu = False,\n",
    "\tlogging_steps = 1,\n",
    "\t# gradient_accumulation_steps=2,\n",
    "\thub_token = hg_token,\n",
    "\thub_model_id = \"raasikhk/carlos_bert_v2_2\",\n",
    "\tpush_to_hub=True,\n",
    ")\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "from numpy import ndarray\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "def get_next_image_number(directory: str) -> int:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        return 1\n",
    "    images = glob.glob(os.path.join(directory, '*.png'))\n",
    "    if not images:\n",
    "        return 1\n",
    "    numbers = [int(os.path.basename(image).split('_')[0]) for image in images]\n",
    "    return max(numbers) + 1\n",
    "\n",
    "def plot_confusion_matrix(cm, save_path, title):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(cm))\n",
    "    plt.xticks(tick_marks, tick_marks, rotation=45)\n",
    "    plt.yticks(tick_marks, tick_marks)\n",
    "    \n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm[i])):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def my_accuracy_score(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[int, int, int, int]:\n",
    "    directory = 'cm'\n",
    "    image_number = get_next_image_number(directory)\n",
    "    \n",
    "    labels = [\"Subjective\", \"Gender\", \"Jargon\", \"Social\"]\n",
    "    true_pos_list, false_pos_list, true_neg_list, false_neg_list = [], [], [], []\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        save_path = os.path.join(directory, f'{image_number}_{label}.png')\n",
    "        \n",
    "        # Calculate confusion matrix for the current label\n",
    "        cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(cm, save_path, f'Confusion Matrix - {label}')\n",
    "        \n",
    "        # Calculate true positives, false positives, true negatives, false negatives\n",
    "        true_pos = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 1))\n",
    "        false_pos = np.sum((y_true[:, i] == 0) & (y_pred[:, i] == 1))\n",
    "        true_neg = np.sum((y_true[:, i] == 0) & (y_pred[:, i] == 0))\n",
    "        false_neg = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 0))\n",
    "        \n",
    "        true_pos_list.append(true_pos)\n",
    "        false_pos_list.append(false_pos)\n",
    "        true_neg_list.append(true_neg)\n",
    "        false_neg_list.append(false_neg)\n",
    "    \n",
    "    return (\n",
    "        sum(true_pos_list), sum(false_pos_list), \n",
    "        sum(true_neg_list), sum(false_neg_list)\n",
    "    )\n",
    "\n",
    "\n",
    "def partial_accuracy_score(y_true: ndarray, y_pred: ndarray):\n",
    "\tnum_objects = len(y_true)\n",
    "\tnum_labels = len(y_true)*4\n",
    "\tcorrect_predictions = 0\n",
    "\t\n",
    "\tfor i in range(num_objects):\n",
    "\t\tfor j in range(len(y_true[i])):\n",
    "\t\t\tif y_true[i][j] == y_pred[i][j]:\n",
    "\t\t\t\tcorrect_predictions += 1\n",
    "\t\n",
    "\taccuracy = correct_predictions / num_labels\n",
    "\treturn accuracy\n",
    "\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "\t# first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "\tsigmoid = torch.nn.Sigmoid()\n",
    "\tprobs = sigmoid(torch.Tensor(predictions))\n",
    "\t# next, use threshold to turn them into integer predictions\n",
    "\ty_pred = np.zeros(probs.shape)\n",
    "\ty_pred[np.where(probs >= threshold)] = 1\n",
    "\t# finally, compute metrics\n",
    "\ty_true = labels\n",
    "\tf1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "\troc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "\taccuracy = accuracy_score(y_true, y_pred)\n",
    "\tmyacc = partial_accuracy_score(y_true, y_pred)\n",
    "\ttrue_pos, false_pos, true_neg, false_neg = my_accuracy_score(y_true, y_pred)\n",
    "\t# return as dictionary\n",
    "\tmetrics = {'f1': f1_micro_average,\n",
    "\t\t\t\t'roc_auc': roc_auc,\n",
    "\t\t\t\t'exact_match_acc': accuracy,\n",
    "\t\t\t\t\"partial_acc\": myacc,\n",
    "\t\t\t\t'true_pos': true_pos,\n",
    "        \t\t'true_neg': true_neg,\n",
    "        \t\t'false_neg': false_neg,\n",
    "\t\t\t\t'false_pos': false_pos}\n",
    "\treturn metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "\tpreds = p.predictions[0] if isinstance(p.predictions, \n",
    "\t\t\ttuple) else p.predictions\n",
    "\tresult = multi_label_metrics(\n",
    "\t\tpredictions=preds, \n",
    "\t\tlabels=p.label_ids)\n",
    "\treturn result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "\tmodel,\n",
    "\targs,\n",
    "\ttrain_dataset=encoded_dataset[\"train\"],\n",
    "\teval_dataset=encoded_dataset[\"validation\"],\n",
    "\ttokenizer=tokenizer,\n",
    "\tcompute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TrainOutput(global_step=5430, training_loss=0.039493819055855826, metrics={'train_runtime': 1080.8201, 'train_samples_per_second': 40.081, 'train_steps_per_second': 5.024, 'total_flos': 1.139817559375872e+16, 'train_loss': 0.039493819055855826, 'epoch': 30.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'eval_loss': 0.2363041341304779,\n",
    " 'eval_f1': 0.8076923076923078,\n",
    " 'eval_roc_auc': 0.8846526655896608,\n",
    " 'eval_exact_match_acc': 0.8232044198895028,\n",
    " 'eval_partial_acc': 0.9447513812154696,\n",
    " 'eval_true_pos': 84,\n",
    " 'eval_true_neg': 600,\n",
    " 'eval_false_neg': 21,\n",
    " 'eval_false_pos': 19,\n",
    " 'eval_runtime': 2.0471,\n",
    " 'eval_samples_per_second': 88.418,\n",
    " 'eval_steps_per_second': 11.235,\n",
    " 'epoch': 30.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.17.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "W0728 22:40:25.041640 13145059328 application.py:559] path / ( not found, sending 404\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# view logs (only needed for analysis)\n",
    "# !pip install tensorboard\n",
    "!tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"model\")\n",
    "# tokenizer.save_pretrained(\"tokenizer\")\n",
    "# tokenizer = transformers.BertTokenizer.from_pretrained(\"tokenizer\")\n",
    "# model = transformers.BertForSequenceClassification.from_pretrained(\"model/checkpoint-1200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a description\n",
    "text = \"December 1992 lead-in term added. January 1991 alternate term added. Object fumigated in Orkin's Piedmont vault with Vikane in 1994\"\n",
    "\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "\n",
    "outputs = trainer.model(**encoding)\n",
    "\n",
    "logits = outputs.logits\n",
    "logits.shape\n",
    "\n",
    "# apply sigmoid + threshold\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(logits.squeeze().cpu())\n",
    "print(probs)\n",
    "predictions = np.zeros(probs.shape)\n",
    "predictions[np.where(probs >= 0.5)] = 1\n",
    "# turn predicted id's into actual label names\n",
    "predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREDICTION**\n",
    "\n",
    "Run the first code block only if you have the model folder and have NOT done training above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "-----------------------------------------------------------------------------\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [{'label': 'Gender', 'score': 0.004395599011331797}, {'label': 'Jargon', 'score': 0.000956284289713949}, {'label': 'Social', 'score': 0.0007053712615743279}, {'label': 'Subjective', 'score': 0.0005113485385663807}]\n",
      "\n",
      "Predictions: [{'label': 'Social', 'score': 0.0009140230249613523}, {'label': 'Jargon', 'score': 0.0008923451532609761}, {'label': 'Gender', 'score': 0.0007808777736499906}, {'label': 'Subjective', 'score': 0.0006347782327793539}]\n",
      "\n",
      "Predictions: [{'label': 'Gender', 'score': 0.980651319026947}, {'label': 'Social', 'score': 0.014727555215358734}, {'label': 'Jargon', 'score': 0.005251614842563868}, {'label': 'Subjective', 'score': 0.004072020761668682}]\n",
      "\n",
      "Predictions: [{'label': 'Gender', 'score': 0.980651319026947}, {'label': 'Social', 'score': 0.014727555215358734}, {'label': 'Jargon', 'score': 0.005251614842563868}, {'label': 'Subjective', 'score': 0.004072020761668682}]\n",
      "\n",
      "Predictions: [{'label': 'Subjective', 'score': 0.994642972946167}, {'label': 'Jargon', 'score': 0.9942375421524048}, {'label': 'Gender', 'score': 0.010229282081127167}, {'label': 'Social', 'score': 0.004664602689445019}]\n",
      "\n",
      "Predictions: [{'label': 'Jargon', 'score': 0.0030346079729497433}, {'label': 'Gender', 'score': 0.0005687834927812219}, {'label': 'Social', 'score': 0.0005162757588550448}, {'label': 'Subjective', 'score': 0.0004150088643655181}]\n",
      "\n",
      "Predictions: [{'label': 'Jargon', 'score': 0.9962565898895264}, {'label': 'Gender', 'score': 0.001455871039070189}, {'label': 'Subjective', 'score': 0.001031916355714202}, {'label': 'Social', 'score': 0.000902624218724668}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST THE MODEL\n",
    "# IF YOU DONT WANT TO TRAIN LOAD MODEL FROM HUGGINGFACE\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# if tokenizer == None:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"raasikhk/carlos_bert_v2_2\", revision=\"4f6590dd149a1cf31d0cc09fa6e2db13fdfc15f1\")\n",
    "# if model == None:\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"raasikhk/carlos_bert_v2_2\", revision=\"4f6590dd149a1cf31d0cc09fa6e2db13fdfc15f1\")\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=None, truncation=True, padding=True, device=device)\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"\"\"Permanent collection gallery:\n",
    "MALE FIGURE\n",
    "\n",
    "This figure exhibits the general geometric body shape, raised geometric facial features, and domed head shape common to the masks and figures of the Widekum sculptural tradition.  The top of the head, badly weathered and insect-damaged, may have had a crest like those found on many Widekum masks.  This figure is probably from an ancestral shrine.\n",
    "\n",
    "Cameroon, Upper Cross River Region, Widekum (?)  20th century.  Wood, pigment.  1994.4.689\n",
    "\n",
    "March 1993 guide term moved.\n",
    "\n",
    "Object fumigated in Orkin's Piedmont vault with Vikane in 1994\n",
    "\n",
    "location verified, inventory 2001.  Turner inventory, April 2004.  Location verified, inventory 9, Winter 2005.\"\"\",\n",
    "    \"Permanent collection gallery\",\n",
    "\t\"Male Figure\",\n",
    "    \"MALE FIGURE\",\n",
    "    \"This figure exhibits the general geometric body shape, raised geometric facial features, and domed head shape common to the masks and figures of the Widekum sculptural tradition.  The top of the head, badly weathered and insect-damaged, may have had a crest like those found on many Widekum masks.  This figure is probably from an ancestral shrine.\",\n",
    "    \"Cameroon, Upper Cross River Region, Widekum (?)  20th century.  Wood, pigment.  1994.4.689\"\n",
    "    \"March 1993 guide term moved.\",\n",
    "    \"Object fumigated in Orkin's Piedmont vault with Vikane in 1994\"\n",
    "    \n",
    "]\n",
    "\n",
    "# Make predictions\n",
    "predictions = pipe(texts)\n",
    "\n",
    "# Print the predictions\n",
    "for i, text in enumerate(texts):\n",
    "    # print(f\"Text: {text}\")\n",
    "    print(f\"Predictions: {predictions[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ACCURACY: 0.8333333333333334\n",
      "PARTIAL ACCURACY: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE ACCURACY\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "\n",
    "unclean = False\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"raasikhk/carlos_bert_v2_2\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"raasikhk/carlos_bert_v2_2\")\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=None, truncation=True, padding=True, device=device)\n",
    "if unclean:\n",
    "\tunclean_df = pd.read_excel(\"../../../carlos_data/preprocessed_data_v3.xlsx\")\n",
    "\tunclean_df = unclean_df.drop(['Social', 'Jargon', 'Subjective', 'Gender'], axis=1)\n",
    "\n",
    "\t# Replace with test dataset\n",
    "\ttest_split = dataset[\"test\"]\n",
    "\ttest_split = pd.DataFrame(test_split)\n",
    "\ttest_split = test_split.drop(['Social', 'Jargon', 'Subjective', 'Gender'], axis=1)\n",
    "\n",
    "\t# Merge test_descriptions with unclean_df on ObjectID\n",
    "\tmerged_df = test_split.merge(unclean_df, on=\"ObjectID\", suffixes=('', '_unclean'), how='left')\n",
    "\n",
    "\t# Extract the newly replaced descriptions\n",
    "\tnew_descriptions = merged_df[\"TextEntry\"].values\n",
    "\n",
    "\t# Get list of unclean descriptions\n",
    "\ttest_descriptions = new_descriptions.tolist()\n",
    "else:\n",
    "    test_descriptions = dataset[\"test\"][\"Description\"]\n",
    "\n",
    "# make predictions variable of the format\n",
    "# -----------------------\n",
    "# bias1 bias2 bias3 bias4\n",
    "# -----------------------\n",
    "#  1     0     1     0\n",
    "#  0     1     0     1\n",
    "#  0     1     0     0\n",
    "# ...   ...   ...   ...\n",
    "predictions = np.zeros((len(test_descriptions), 4), int)\n",
    "\n",
    "for i in range(len(test_descriptions)):\n",
    "    pred = pipe(test_descriptions[i])\n",
    "    for j in range(4):\n",
    "        label = pred[0][j][\"label\"]\n",
    "        score = pred[0][j][\"score\"]\n",
    "        if label == \"Subjective\":\n",
    "            predictions[i][0] = 1 if score >= 0.5 else 0\n",
    "        elif label == \"Gender\":\n",
    "            predictions[i][1] = 1 if score >= 0.5 else 0\n",
    "        elif label == \"Jargon\":\n",
    "            predictions[i][2] = 1 if score >= 0.5 else 0\n",
    "        elif label == \"Social\":\n",
    "            predictions[i][3] = 1 if score >= 0.5 else 0\n",
    "\n",
    "# merge classifications of each bias column wise to create matrix:\n",
    "# subj0   gend0   jarg0   soci0\n",
    "# subj0   gend0   jarg0   soci0\n",
    "# subj0   gend0   jarg0   soci0\n",
    "true_values = np.column_stack((dataset[\"test\"][\"Subjective\"], dataset[\"test\"][\"Gender\"], \n",
    "                               dataset[\"test\"][\"Jargon\"], dataset[\"test\"][\"Social\"]))\n",
    "\n",
    "# Use Scikit-learn method\n",
    "print(f\"ALL ACCURACY: {accuracy_score(true_values, predictions)}\")\n",
    "\n",
    "# Calculate partial accuracy\n",
    "part_acc_score = 0\n",
    "total = true_values.size  # Or predictions.size, since both have the same shape\n",
    "\n",
    "for i in range(true_values.shape[0]):\n",
    "    for j in range(true_values.shape[1]):\n",
    "        if true_values[i][j] == predictions[i][j]:\n",
    "            part_acc_score += 1\n",
    "\n",
    "print(f\"PARTIAL ACCURACY: {part_acc_score/total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
